{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07597e48",
   "metadata": {},
   "source": [
    "### 01 - Setup and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd32656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó SPARK_MASTER      : spark://spark-master:7077\n",
      "üß∑ DRIVER_HOST       : jupyter\n",
      "üß≠ POLARIS_URI       : http://polaris:8181/api/catalog\n",
      "üì¶ ICEBERG_WAREHOUSE : s3://warehouse/iceberg\n",
      "ü™£ S3 endpoint       : http://minio:9000\n",
      "‚úÖ Spark up.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Sanity spark.range(10).count() = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# Polaris\n",
    "POLARIS_URI = os.getenv(\"POLARIS_URI\", \"http://polaris:8181/api/catalog\").rstrip(\"/\")\n",
    "POLARIS_OAUTH2 = os.getenv(\"POLARIS_OAUTH2_TOKEN_URL\", \"http://polaris:8181/api/catalog/v1/oauth/tokens\")\n",
    "POLARIS_SCOPE = os.getenv(\"POLARIS_SCOPE\", \"PRINCIPAL_ROLE:ALL\")\n",
    "POLARIS_CLIENT_ID = os.getenv(\"POLARIS_CLIENT_ID\", \"admin\")\n",
    "POLARIS_CLIENT_SECRET = os.getenv(\"POLARIS_CLIENT_SECRET\", \"password\")\n",
    "\n",
    "# Spark\n",
    "SPARK_MASTER = os.getenv(\"SPARK_MASTER\", \"spark://spark-master:7077\")\n",
    "DRIVER_HOST = os.getenv(\"SPARK_DRIVER_HOST\", \"jupyter\")  # docker service name\n",
    "\n",
    "# MinIO / S3A\n",
    "S3_ENDPOINT = os.getenv(\"S3_ENDPOINT\", \"http://minio:9000\")\n",
    "S3_ACCESS_KEY = os.getenv(\"MINIO_ROOT_USER\", \"minioadmin\")\n",
    "S3_SECRET_KEY = os.getenv(\"MINIO_ROOT_PASSWORD\", \"minioadmin\")\n",
    "\n",
    "# Iceberg files location\n",
    "ICEBERG_WAREHOUSE = os.getenv(\"ICEBERG_WAREHOUSE\", \"s3://warehouse/polaris\").strip()\n",
    "if ICEBERG_WAREHOUSE.startswith(\"s3a://\"):\n",
    "    ICEBERG_WAREHOUSE = f\"s3://{ICEBERG_WAREHOUSE[len('s3a://') :]}\"\n",
    "\n",
    "\n",
    "# Stop oude sessie\n",
    "if \"spark\" in locals():\n",
    "    try:\n",
    "        spark.stop()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(f\"üîó SPARK_MASTER      : {SPARK_MASTER}\")\n",
    "print(f\"üß∑ DRIVER_HOST       : {DRIVER_HOST}\")\n",
    "print(f\"üß≠ POLARIS_URI       : {POLARIS_URI}\")\n",
    "print(f\"üì¶ ICEBERG_WAREHOUSE : {ICEBERG_WAREHOUSE}\")\n",
    "print(f\"ü™£ S3 endpoint       : {S3_ENDPOINT}\")\n",
    "\n",
    "builder = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Lakehouse-Unplugged\")\n",
    "    .master(SPARK_MASTER)\n",
    "    .config(\"spark.driver.host\", DRIVER_HOST)\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.defaultCatalog\", \"spark_catalog\")\n",
    "\n",
    "    # Polaris catalog (gebruik via polaris.<ns>.<table>)\n",
    "    .config(\"spark.sql.catalog.polaris\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.polaris.type\", \"rest\")\n",
    "    .config(\"spark.sql.catalog.polaris.uri\", POLARIS_URI)\n",
    "    .config(\"spark.sql.catalog.polaris.warehouse\", ICEBERG_WAREHOUSE)\n",
    "    .config(\"spark.sql.catalog.polaris.rest.auth.type\", \"oauth2\")\n",
    "    .config(\"spark.sql.catalog.polaris.credential\", f\"{POLARIS_CLIENT_ID}:{POLARIS_CLIENT_SECRET}\")\n",
    "    .config(\"spark.sql.catalog.polaris.oauth2-server-uri\", POLARIS_OAUTH2)\n",
    "    .config(\"spark.sql.catalog.polaris.scope\", POLARIS_SCOPE)\n",
    "    .config(\"spark.sql.catalog.polaris.token-refresh-enabled\", \"true\")\n",
    "\n",
    "    # Iceberg FileIO via AWS bundle (werkt met s3:// en MinIO)\n",
    "    .config(\"spark.sql.catalog.polaris.io-impl\", \"org.apache.iceberg.aws.s3.S3FileIO\")\n",
    "    .config(\"spark.sql.catalog.polaris.s3.endpoint\", S3_ENDPOINT)\n",
    "    .config(\"spark.sql.catalog.polaris.s3.path-style-access\", \"true\")\n",
    "    .config(\"spark.sql.catalog.polaris.s3.access-key-id\", S3_ACCESS_KEY)\n",
    "    .config(\"spark.sql.catalog.polaris.s3.secret-access-key\", S3_SECRET_KEY)\n",
    "    .config(\"spark.sql.catalog.polaris.s3.region\", \"us-east-1\")\n",
    "\n",
    "    # S3A / MinIO (data files)\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", S3_ENDPOINT)\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", S3_ACCESS_KEY)\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", S3_SECRET_KEY)\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"4\")\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    ")\n",
    "\n",
    "pkgs = (os.getenv(\"SPARK_JARS_PACKAGES\") or \"\").strip()\n",
    "if pkgs:\n",
    "    print(f\"‚ö†Ô∏è spark.jars.packages staat aan (driver downloadt deps): {pkgs}\")\n",
    "    builder = builder.config(\"spark.jars.packages\", pkgs)\n",
    "\n",
    "spark = builder.getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark up.\")\n",
    "print(\"üß™ Sanity spark.range(10).count() =\", spark.range(10).count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02 - Parkeer bestande in de landingzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d4a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Lokaal bestand : /workspace/data/gekentekendevoertuigen_sample.json\n",
      "‚¨ÜÔ∏è Upload naar    : s3://warehouse/landing/gekentekendevoertuigen_sample.json\n",
      "üì• Spark read via : s3a://warehouse/landing/gekentekendevoertuigen_sample.json\n",
      "ü™£ MinIO endpoint : http://minio:9000\n",
      "‚úÖ Upload gelukt.\n",
      "üì¶ Objecten in MinIO:\n",
      " - landing/gekentekendevoertuigen_sample.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Aantal records: 10,000\n",
      "root\n",
      " |-- aanhangwagen_autonoom_geremd: string (nullable = true)\n",
      " |-- aanhangwagen_middenas_geremd: string (nullable = true)\n",
      " |-- aantal_cilinders: string (nullable = true)\n",
      " |-- aantal_deuren: string (nullable = true)\n",
      " |-- aantal_rolstoelplaatsen: string (nullable = true)\n",
      " |-- aantal_staanplaatsen: string (nullable = true)\n",
      " |-- aantal_wielen: string (nullable = true)\n",
      " |-- aantal_zitplaatsen: string (nullable = true)\n",
      " |-- afstand_hart_koppeling_tot_achterzijde_voertuig: string (nullable = true)\n",
      " |-- afstand_voorzijde_voertuig_tot_hart_koppeling: string (nullable = true)\n",
      " |-- afwijkende_maximum_snelheid: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_assen: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_brandstof: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_carrosserie: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_carrosserie_specifiek: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_voertuigklasse: string (nullable = true)\n",
      " |-- breedte: string (nullable = true)\n",
      " |-- breedte_voertuig_maximum: string (nullable = true)\n",
      " |-- breedte_voertuig_minimum: string (nullable = true)\n",
      " |-- bruto_bpm: string (nullable = true)\n",
      " |-- catalogusprijs: string (nullable = true)\n",
      " |-- cilinderinhoud: string (nullable = true)\n",
      " |-- code_toelichting_tellerstandoordeel: string (nullable = true)\n",
      " |-- datum_eerste_tenaamstelling_in_nederland: string (nullable = true)\n",
      " |-- datum_eerste_tenaamstelling_in_nederland_dt: string (nullable = true)\n",
      " |-- datum_eerste_toelating: string (nullable = true)\n",
      " |-- datum_eerste_toelating_dt: string (nullable = true)\n",
      " |-- datum_tenaamstelling: string (nullable = true)\n",
      " |-- datum_tenaamstelling_dt: string (nullable = true)\n",
      " |-- eerste_kleur: string (nullable = true)\n",
      " |-- europese_uitvoeringcategorie_toevoeging: string (nullable = true)\n",
      " |-- europese_voertuigcategorie: string (nullable = true)\n",
      " |-- europese_voertuigcategorie_toevoeging: string (nullable = true)\n",
      " |-- export_indicator: string (nullable = true)\n",
      " |-- handelsbenaming: string (nullable = true)\n",
      " |-- hoogte_voertuig: string (nullable = true)\n",
      " |-- hoogte_voertuig_maximum: string (nullable = true)\n",
      " |-- hoogte_voertuig_minimum: string (nullable = true)\n",
      " |-- inrichting: string (nullable = true)\n",
      " |-- jaar_laatste_registratie_tellerstand: string (nullable = true)\n",
      " |-- kenteken: string (nullable = true)\n",
      " |-- laadvermogen: string (nullable = true)\n",
      " |-- lengte: string (nullable = true)\n",
      " |-- lengte_voertuig_maximum: string (nullable = true)\n",
      " |-- lengte_voertuig_minimum: string (nullable = true)\n",
      " |-- massa_bedrijfsklaar_maximaal: string (nullable = true)\n",
      " |-- massa_bedrijfsklaar_minimaal: string (nullable = true)\n",
      " |-- massa_ledig_voertuig: string (nullable = true)\n",
      " |-- massa_rijklaar: string (nullable = true)\n",
      " |-- maximale_constructiesnelheid: string (nullable = true)\n",
      " |-- maximum_last_onder_de_vooras_sen_tezamen_koppeling: string (nullable = true)\n",
      " |-- maximum_massa_samenstelling: string (nullable = true)\n",
      " |-- maximum_massa_technisch_maximaal: string (nullable = true)\n",
      " |-- maximum_massa_technisch_minimaal: string (nullable = true)\n",
      " |-- maximum_massa_trekken_ongeremd: string (nullable = true)\n",
      " |-- maximum_ondersteunende_snelheid: string (nullable = true)\n",
      " |-- maximum_trekken_massa_geremd: string (nullable = true)\n",
      " |-- merk: string (nullable = true)\n",
      " |-- openstaande_terugroepactie_indicator: string (nullable = true)\n",
      " |-- oplegger_geremd: string (nullable = true)\n",
      " |-- plaats_chassisnummer: string (nullable = true)\n",
      " |-- registratie_datum_goedkeuring_afschrijvingsmoment_bpm: string (nullable = true)\n",
      " |-- registratie_datum_goedkeuring_afschrijvingsmoment_bpm_dt: string (nullable = true)\n",
      " |-- subcategorie_nederland: string (nullable = true)\n",
      " |-- taxi_indicator: string (nullable = true)\n",
      " |-- technische_max_massa_voertuig: string (nullable = true)\n",
      " |-- tellerstandoordeel: string (nullable = true)\n",
      " |-- tenaamstellen_mogelijk: string (nullable = true)\n",
      " |-- toegestane_maximum_massa_voertuig: string (nullable = true)\n",
      " |-- tweede_kleur: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- type_gasinstallatie: string (nullable = true)\n",
      " |-- typegoedkeuringsnummer: string (nullable = true)\n",
      " |-- uitvoering: string (nullable = true)\n",
      " |-- variant: string (nullable = true)\n",
      " |-- vermogen_massarijklaar: string (nullable = true)\n",
      " |-- verticale_belasting_koppelpunt_getrokken_voertuig: string (nullable = true)\n",
      " |-- vervaldatum_apk: string (nullable = true)\n",
      " |-- vervaldatum_apk_dt: string (nullable = true)\n",
      " |-- vervaldatum_tachograaf: string (nullable = true)\n",
      " |-- vervaldatum_tachograaf_dt: string (nullable = true)\n",
      " |-- voertuigsoort: string (nullable = true)\n",
      " |-- volgnummer_wijziging_eu_typegoedkeuring: string (nullable = true)\n",
      " |-- wacht_op_keuren: string (nullable = true)\n",
      " |-- wam_verzekerd: string (nullable = true)\n",
      " |-- wielbasis: string (nullable = true)\n",
      " |-- wielbasis_voertuig_maximum: string (nullable = true)\n",
      " |-- wielbasis_voertuig_minimum: string (nullable = true)\n",
      " |-- zuinigheidsclassificatie: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/06 16:16:52 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------+----------------+-------------+-----------------------+--------------------+-------------+------------------+-----------------------------------------------+---------------------------------------------+---------------------------+-----------------------------------------------+-----------------------------------------------+-----------------------------------------------+-------------------------------------------------+-----------------------------------------------+-------+------------------------+------------------------+---------+--------------+--------------+-----------------------------------+----------------------------------------+-------------------------------------------+----------------------+-------------------------+--------------------+-----------------------+------------+---------------------------------------+--------------------------+-------------------------------------+----------------+---------------+---------------+-----------------------+-----------------------+--------------------+------------------------------------+--------+------------+------+-----------------------+-----------------------+----------------------------+----------------------------+--------------------+--------------+----------------------------+--------------------------------------------------+---------------------------+--------------------------------+--------------------------------+------------------------------+-------------------------------+----------------------------+---------+------------------------------------+---------------+-----------------------------------+-----------------------------------------------------+--------------------------------------------------------+----------------------+--------------+-----------------------------+------------------+----------------------+---------------------------------+------------------+-----+-------------------+----------------------+--------------------+-------+----------------------+-------------------------------------------------+---------------+-----------------------+----------------------+-------------------------+-------------+---------------------------------------+------------------------------+-------------+---------+--------------------------+--------------------------+------------------------+\n",
      "|aanhangwagen_autonoom_geremd|aanhangwagen_middenas_geremd|aantal_cilinders|aantal_deuren|aantal_rolstoelplaatsen|aantal_staanplaatsen|aantal_wielen|aantal_zitplaatsen|afstand_hart_koppeling_tot_achterzijde_voertuig|afstand_voorzijde_voertuig_tot_hart_koppeling|afwijkende_maximum_snelheid|api_gekentekende_voertuigen_assen              |api_gekentekende_voertuigen_brandstof          |api_gekentekende_voertuigen_carrosserie        |api_gekentekende_voertuigen_carrosserie_specifiek|api_gekentekende_voertuigen_voertuigklasse     |breedte|breedte_voertuig_maximum|breedte_voertuig_minimum|bruto_bpm|catalogusprijs|cilinderinhoud|code_toelichting_tellerstandoordeel|datum_eerste_tenaamstelling_in_nederland|datum_eerste_tenaamstelling_in_nederland_dt|datum_eerste_toelating|datum_eerste_toelating_dt|datum_tenaamstelling|datum_tenaamstelling_dt|eerste_kleur|europese_uitvoeringcategorie_toevoeging|europese_voertuigcategorie|europese_voertuigcategorie_toevoeging|export_indicator|handelsbenaming|hoogte_voertuig|hoogte_voertuig_maximum|hoogte_voertuig_minimum|inrichting          |jaar_laatste_registratie_tellerstand|kenteken|laadvermogen|lengte|lengte_voertuig_maximum|lengte_voertuig_minimum|massa_bedrijfsklaar_maximaal|massa_bedrijfsklaar_minimaal|massa_ledig_voertuig|massa_rijklaar|maximale_constructiesnelheid|maximum_last_onder_de_vooras_sen_tezamen_koppeling|maximum_massa_samenstelling|maximum_massa_technisch_maximaal|maximum_massa_technisch_minimaal|maximum_massa_trekken_ongeremd|maximum_ondersteunende_snelheid|maximum_trekken_massa_geremd|merk     |openstaande_terugroepactie_indicator|oplegger_geremd|plaats_chassisnummer               |registratie_datum_goedkeuring_afschrijvingsmoment_bpm|registratie_datum_goedkeuring_afschrijvingsmoment_bpm_dt|subcategorie_nederland|taxi_indicator|technische_max_massa_voertuig|tellerstandoordeel|tenaamstellen_mogelijk|toegestane_maximum_massa_voertuig|tweede_kleur      |type |type_gasinstallatie|typegoedkeuringsnummer|uitvoering          |variant|vermogen_massarijklaar|verticale_belasting_koppelpunt_getrokken_voertuig|vervaldatum_apk|vervaldatum_apk_dt     |vervaldatum_tachograaf|vervaldatum_tachograaf_dt|voertuigsoort|volgnummer_wijziging_eu_typegoedkeuring|wacht_op_keuren               |wam_verzekerd|wielbasis|wielbasis_voertuig_maximum|wielbasis_voertuig_minimum|zuinigheidsclassificatie|\n",
      "+----------------------------+----------------------------+----------------+-------------+-----------------------+--------------------+-------------+------------------+-----------------------------------------------+---------------------------------------------+---------------------------+-----------------------------------------------+-----------------------------------------------+-----------------------------------------------+-------------------------------------------------+-----------------------------------------------+-------+------------------------+------------------------+---------+--------------+--------------+-----------------------------------+----------------------------------------+-------------------------------------------+----------------------+-------------------------+--------------------+-----------------------+------------+---------------------------------------+--------------------------+-------------------------------------+----------------+---------------+---------------+-----------------------+-----------------------+--------------------+------------------------------------+--------+------------+------+-----------------------+-----------------------+----------------------------+----------------------------+--------------------+--------------+----------------------------+--------------------------------------------------+---------------------------+--------------------------------+--------------------------------+------------------------------+-------------------------------+----------------------------+---------+------------------------------------+---------------+-----------------------------------+-----------------------------------------------------+--------------------------------------------------------+----------------------+--------------+-----------------------------+------------------+----------------------+---------------------------------+------------------+-----+-------------------+----------------------+--------------------+-------+----------------------+-------------------------------------------------+---------------+-----------------------+----------------------+-------------------------+-------------+---------------------------------------+------------------------------+-------------+---------+--------------------------+--------------------------+------------------------+\n",
      "|NULL                        |NULL                        |NULL            |NULL         |NULL                   |NULL                |NULL         |NULL              |419                                            |NULL                                         |NULL                       |https://opendata.rdw.nl/resource/3huj-srit.json|https://opendata.rdw.nl/resource/8ys7-d773.json|https://opendata.rdw.nl/resource/vezc-m2t6.json|https://opendata.rdw.nl/resource/jhie-znh9.json  |https://opendata.rdw.nl/resource/kmfi-hrps.json|174    |NULL                    |NULL                    |NULL     |NULL          |NULL          |NG                                 |19780914                                |1978-09-14T00:00:00.000                    |19780914              |1978-09-14T00:00:00.000  |20221201            |2022-12-01T00:00:00.000|N.v.t.      |NULL                                   |O2                        |NULL                                 |Nee             |P.T.A.-1500    |NULL           |NULL                   |NULL                   |open wagen          |NULL                                |0039WG  |1090        |NULL  |NULL                   |NULL                   |NULL                        |NULL                        |410                 |NULL          |100                         |0                                                 |NULL                       |NULL                            |NULL                            |NULL                          |NULL                           |NULL                        |PIJNAPPEL|Nee                                 |NULL           |tegen r. balk 130 cm v. hart asstel|NULL                                                 |NULL                                                    |NULL                  |Nee           |1500                         |Niet geregistreerd|Ja                    |1500                             |N.v.t.            |NULL |NULL               |NULL                  |NULL                |NULL   |NULL                  |NULL                                             |NULL           |NULL                   |NULL                  |NULL                     |Aanhangwagen |NULL                                   |Geen verstrekking in Open Data|N.v.t.       |NULL     |NULL                      |NULL                      |NULL                    |\n",
      "|28928                       |14369                       |6               |NULL         |NULL                   |NULL                |8            |2                 |NULL                                           |908                                          |NULL                       |https://opendata.rdw.nl/resource/3huj-srit.json|https://opendata.rdw.nl/resource/8ys7-d773.json|https://opendata.rdw.nl/resource/vezc-m2t6.json|https://opendata.rdw.nl/resource/jhie-znh9.json  |https://opendata.rdw.nl/resource/kmfi-hrps.json|255    |NULL                    |NULL                    |NULL     |NULL          |10837         |NG                                 |20160325                                |2016-03-25T00:00:00.000                    |20160325              |2016-03-25T00:00:00.000  |20221201            |2022-12-01T00:00:00.000|N.v.t.      |NULL                                   |N3                        |NULL                                 |Nee             |XF 440 FAN     |NULL           |NULL                   |NULL                   |afneembare bovenbouw|NULL                                |00BHB9  |17155       |1003  |NULL                   |NULL                   |NULL                        |NULL                        |9845                |9945          |NULL                        |0                                                 |50000                      |NULL                            |NULL                            |750                           |NULL                           |NULL                        |DAF      |Nee                                 |NULL           |r. vooras                          |NULL                                                 |NULL                                                    |NULL                  |Nee           |27000                        |Niet geregistreerd|Ja                    |27000                            |N.v.t.            |H4SN3|NULL               |NULL                  |NULL                |NULL   |0.03                  |NULL                                             |20231211       |2023-12-11T00:00:00.000|20241201              |2024-12-01T00:00:00.000  |Bedrijfsauto |NULL                                   |Geen verstrekking in Open Data|Ja           |670      |NULL                      |NULL                      |NULL                    |\n",
      "|NULL                        |NULL                        |6               |2            |0                      |NULL                |6            |2                 |0                                              |459                                          |NULL                       |https://opendata.rdw.nl/resource/3huj-srit.json|https://opendata.rdw.nl/resource/8ys7-d773.json|https://opendata.rdw.nl/resource/vezc-m2t6.json|https://opendata.rdw.nl/resource/jhie-znh9.json  |https://opendata.rdw.nl/resource/kmfi-hrps.json|255    |NULL                    |NULL                    |NULL     |NULL          |12777         |NG                                 |20221125                                |2022-11-25T00:00:00.000                    |20220927              |2022-09-27T00:00:00.000  |20221201            |2022-12-01T00:00:00.000|N.v.t.      |NULL                                   |N3                        |NULL                                 |Nee             |FH             |NULL           |NULL                   |NULL                   |opleggertrekker     |NULL                                |00BTR3  |NULL        |621   |NULL                   |NULL                   |NULL                        |NULL                        |8484                |8584          |90                          |NULL                                              |44000                      |NULL                            |NULL                            |NULL                          |0.00                           |NULL                        |VOLVO    |Nee                                 |35416          |r. balk by vooras                  |20221115                                             |2022-11-15T00:00:00.000                                 |NULL                  |Nee           |20500                        |Niet geregistreerd|Ja                    |19000                            |N.v.t.            |VTA3T|NULL               |e5*2007/46*1013*12    |N5RR3S67513XX3M5TUUC|C3FHA1 |0.04                  |NULL                                             |20230927       |2023-09-27T00:00:00.000|20241125              |2024-11-25T00:00:00.000  |Bedrijfsauto |0                                      |Geen verstrekking in Open Data|Ja           |380      |NULL                      |NULL                      |NULL                    |\n",
      "|NULL                        |NULL                        |4               |2            |0                      |NULL                |4            |5                 |0                                              |0                                            |NULL                       |https://opendata.rdw.nl/resource/3huj-srit.json|https://opendata.rdw.nl/resource/8ys7-d773.json|https://opendata.rdw.nl/resource/vezc-m2t6.json|https://opendata.rdw.nl/resource/jhie-znh9.json  |https://opendata.rdw.nl/resource/kmfi-hrps.json|0      |NULL                    |NULL                    |2152     |14469         |1396          |00                                 |20090617                                |2009-06-17T00:00:00.000                    |20090617              |2009-06-17T00:00:00.000  |20221201            |2022-12-01T00:00:00.000|GRIJS       |NULL                                   |M1                        |NULL                                 |Nee             |I20            |NULL           |NULL                   |NULL                   |MPV                 |2022                                |00JJT8  |NULL        |394   |NULL                   |NULL                   |NULL                        |NULL                        |1000                |1100          |NULL                        |NULL                                              |2565                       |NULL                            |NULL                            |450                           |NULL                           |1000                        |HYUNDAI  |Nee                                 |NULL           |r. dwarsbalk by voorzitting        |NULL                                                 |NULL                                                    |NULL                  |Nee           |1565                         |Logisch           |Ja                    |1565                             |Niet geregistreerd|PB   |NULL               |e11*2001/116*0333*01  |M52AY1              |F5P21  |0.07                  |NULL                                             |20230317       |2023-03-17T00:00:00.000|NULL                  |NULL                     |Personenauto |0                                      |Geen verstrekking in Open Data|Ja           |253      |NULL                      |NULL                      |B                       |\n",
      "|NULL                        |NULL                        |4               |2            |0                      |NULL                |4            |4                 |0                                              |0                                            |NULL                       |https://opendata.rdw.nl/resource/3huj-srit.json|https://opendata.rdw.nl/resource/8ys7-d773.json|https://opendata.rdw.nl/resource/vezc-m2t6.json|https://opendata.rdw.nl/resource/jhie-znh9.json  |https://opendata.rdw.nl/resource/kmfi-hrps.json|0      |NULL                    |NULL                    |NULL     |15837         |1242          |07                                 |20090717                                |2009-07-17T00:00:00.000                    |20090717              |2009-07-17T00:00:00.000  |20221201            |2022-12-01T00:00:00.000|ROOD        |NULL                                   |M1                        |NULL                                 |Nee             |FIAT 500       |NULL           |NULL                   |NULL                   |hatchback           |2022                                |00JPH6  |NULL        |355   |NULL                   |NULL                   |NULL                        |NULL                        |875                 |975           |NULL                        |NULL                                              |2140                       |NULL                            |NULL                            |400                           |NULL                           |800                         |FIAT     |Nee                                 |NULL           |r. op bodemplaat in kofferruimte   |NULL                                                 |NULL                                                    |NULL                  |Nee           |1340                         |Geen oordeel      |Ja                    |1340                             |Niet geregistreerd|312  |NULL               |e3*2001/116*0261*07   |03C                 |AXA11  |0.05                  |NULL                                             |20230902       |2023-09-02T00:00:00.000|NULL                  |NULL                     |Personenauto |0                                      |Geen verstrekking in Open Data|Ja           |230      |NULL                      |NULL                      |A                       |\n",
      "+----------------------------+----------------------------+----------------+-------------+-----------------------+--------------------+-------------+------------------+-----------------------------------------------+---------------------------------------------+---------------------------+-----------------------------------------------+-----------------------------------------------+-----------------------------------------------+-------------------------------------------------+-----------------------------------------------+-------+------------------------+------------------------+---------+--------------+--------------+-----------------------------------+----------------------------------------+-------------------------------------------+----------------------+-------------------------+--------------------+-----------------------+------------+---------------------------------------+--------------------------+-------------------------------------+----------------+---------------+---------------+-----------------------+-----------------------+--------------------+------------------------------------+--------+------------+------+-----------------------+-----------------------+----------------------------+----------------------------+--------------------+--------------+----------------------------+--------------------------------------------------+---------------------------+--------------------------------+--------------------------------+------------------------------+-------------------------------+----------------------------+---------+------------------------------------+---------------+-----------------------------------+-----------------------------------------------------+--------------------------------------------------------+----------------------+--------------+-----------------------------+------------------+----------------------+---------------------------------+------------------+-----+-------------------+----------------------+--------------------+-------+----------------------+-------------------------------------------------+---------------+-----------------------+----------------------+-------------------------+-------------+---------------------------------------+------------------------------+-------------+---------+--------------------------+--------------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# ======================================================================\n",
    "# 0Ô∏è‚É£ Helper: zoek automatisch lokaal data-bestand\n",
    "# ======================================================================\n",
    "def find_data_file(filename: str) -> Path:\n",
    "    p = Path.cwd()\n",
    "    for _ in range(6):\n",
    "        candidate = p / \"data\" / filename\n",
    "        if candidate.exists():\n",
    "            return candidate\n",
    "        p = p.parent\n",
    "    raise FileNotFoundError(f\"‚ùå Kon '{filename}' niet vinden in een 'data' map vanaf {Path.cwd()}.\")\n",
    "\n",
    "# ======================================================================\n",
    "# 1Ô∏è‚É£ Config (uit env waar kan)\n",
    "# ======================================================================\n",
    "local_file = find_data_file(\"gekentekendevoertuigen_sample.json\")\n",
    "\n",
    "bucket = os.getenv(\"MINIO_BUCKET\", \"warehouse\")\n",
    "prefix = os.getenv(\"MINIO_PREFIX\", \"landing\")\n",
    "\n",
    "endpoint = os.getenv(\"S3_ENDPOINT\", \"http://minio:9000\")\n",
    "access_key = os.getenv(\"MINIO_ROOT_USER\", \"minioadmin\")\n",
    "secret_key = os.getenv(\"MINIO_ROOT_PASSWORD\", \"minioadmin\")\n",
    "region = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "\n",
    "object_key = f\"{prefix}/{local_file.name}\"\n",
    "s3a_uri = f\"s3a://{bucket}/{object_key}\"\n",
    "\n",
    "print(f\"üìÑ Lokaal bestand : {local_file}\")\n",
    "print(f\"‚¨ÜÔ∏è Upload naar    : s3://{bucket}/{object_key}\")\n",
    "print(f\"üì• Spark read via : {s3a_uri}\")\n",
    "print(f\"ü™£ MinIO endpoint : {endpoint}\")\n",
    "\n",
    "# ======================================================================\n",
    "# 2Ô∏è‚É£ MinIO client via boto3 (S3 API)\n",
    "# ======================================================================\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=endpoint,\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    region_name=region,\n",
    ")\n",
    "\n",
    "# Bucket check (minio-setup maakt 'warehouse' al aan, maar dit maakt het robuust)\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket)\n",
    "except ClientError:\n",
    "    print(f\"‚ÑπÔ∏è Bucket '{bucket}' bestaat nog niet, maak 'm aan...\")\n",
    "    s3.create_bucket(Bucket=bucket)\n",
    "\n",
    "# Upload bestand\n",
    "s3.upload_file(str(local_file), bucket, object_key)\n",
    "print(\"‚úÖ Upload gelukt.\")\n",
    "\n",
    "# ======================================================================\n",
    "# 3Ô∏è‚É£ Verify: lijst objecten in prefix\n",
    "# ======================================================================\n",
    "response = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "print(\"üì¶ Objecten in MinIO:\")\n",
    "for item in response.get(\"Contents\", []):\n",
    "    print(\" -\", item[\"Key\"])\n",
    "\n",
    "# ======================================================================\n",
    "# 4Ô∏è‚É£ Spark read via S3A\n",
    "# ======================================================================\n",
    "df = spark.read.option(\"multiline\", \"true\").json(s3a_uri)\n",
    "\n",
    "print(f\"üìä Aantal records: {df.count():,}\")\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03 - Ingest into bronze table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Lezen vanuit landingzone: s3a://warehouse/landing/gekentekendevoertuigen_sample.json\n",
      "+-------------+\n",
      "|catalog      |\n",
      "+-------------+\n",
      "|spark_catalog|\n",
      "+-------------+\n",
      "\n",
      "üì¶ Aantal records geladen: 10,000\n",
      "root\n",
      " |-- aanhangwagen_autonoom_geremd: string (nullable = true)\n",
      " |-- aanhangwagen_middenas_geremd: string (nullable = true)\n",
      " |-- aantal_cilinders: string (nullable = true)\n",
      " |-- aantal_deuren: string (nullable = true)\n",
      " |-- aantal_rolstoelplaatsen: string (nullable = true)\n",
      " |-- aantal_staanplaatsen: string (nullable = true)\n",
      " |-- aantal_wielen: string (nullable = true)\n",
      " |-- aantal_zitplaatsen: string (nullable = true)\n",
      " |-- afstand_hart_koppeling_tot_achterzijde_voertuig: string (nullable = true)\n",
      " |-- afstand_voorzijde_voertuig_tot_hart_koppeling: string (nullable = true)\n",
      " |-- afwijkende_maximum_snelheid: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_assen: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_brandstof: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_carrosserie: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_carrosserie_specifiek: string (nullable = true)\n",
      " |-- api_gekentekende_voertuigen_voertuigklasse: string (nullable = true)\n",
      " |-- breedte: string (nullable = true)\n",
      " |-- breedte_voertuig_maximum: string (nullable = true)\n",
      " |-- breedte_voertuig_minimum: string (nullable = true)\n",
      " |-- bruto_bpm: string (nullable = true)\n",
      " |-- catalogusprijs: string (nullable = true)\n",
      " |-- cilinderinhoud: string (nullable = true)\n",
      " |-- code_toelichting_tellerstandoordeel: string (nullable = true)\n",
      " |-- datum_eerste_tenaamstelling_in_nederland: string (nullable = true)\n",
      " |-- datum_eerste_tenaamstelling_in_nederland_dt: string (nullable = true)\n",
      " |-- datum_eerste_toelating: string (nullable = true)\n",
      " |-- datum_eerste_toelating_dt: string (nullable = true)\n",
      " |-- datum_tenaamstelling: string (nullable = true)\n",
      " |-- datum_tenaamstelling_dt: string (nullable = true)\n",
      " |-- eerste_kleur: string (nullable = true)\n",
      " |-- europese_uitvoeringcategorie_toevoeging: string (nullable = true)\n",
      " |-- europese_voertuigcategorie: string (nullable = true)\n",
      " |-- europese_voertuigcategorie_toevoeging: string (nullable = true)\n",
      " |-- export_indicator: string (nullable = true)\n",
      " |-- handelsbenaming: string (nullable = true)\n",
      " |-- hoogte_voertuig: string (nullable = true)\n",
      " |-- hoogte_voertuig_maximum: string (nullable = true)\n",
      " |-- hoogte_voertuig_minimum: string (nullable = true)\n",
      " |-- inrichting: string (nullable = true)\n",
      " |-- jaar_laatste_registratie_tellerstand: string (nullable = true)\n",
      " |-- kenteken: string (nullable = true)\n",
      " |-- laadvermogen: string (nullable = true)\n",
      " |-- lengte: string (nullable = true)\n",
      " |-- lengte_voertuig_maximum: string (nullable = true)\n",
      " |-- lengte_voertuig_minimum: string (nullable = true)\n",
      " |-- massa_bedrijfsklaar_maximaal: string (nullable = true)\n",
      " |-- massa_bedrijfsklaar_minimaal: string (nullable = true)\n",
      " |-- massa_ledig_voertuig: string (nullable = true)\n",
      " |-- massa_rijklaar: string (nullable = true)\n",
      " |-- maximale_constructiesnelheid: string (nullable = true)\n",
      " |-- maximum_last_onder_de_vooras_sen_tezamen_koppeling: string (nullable = true)\n",
      " |-- maximum_massa_samenstelling: string (nullable = true)\n",
      " |-- maximum_massa_technisch_maximaal: string (nullable = true)\n",
      " |-- maximum_massa_technisch_minimaal: string (nullable = true)\n",
      " |-- maximum_massa_trekken_ongeremd: string (nullable = true)\n",
      " |-- maximum_ondersteunende_snelheid: string (nullable = true)\n",
      " |-- maximum_trekken_massa_geremd: string (nullable = true)\n",
      " |-- merk: string (nullable = true)\n",
      " |-- openstaande_terugroepactie_indicator: string (nullable = true)\n",
      " |-- oplegger_geremd: string (nullable = true)\n",
      " |-- plaats_chassisnummer: string (nullable = true)\n",
      " |-- registratie_datum_goedkeuring_afschrijvingsmoment_bpm: string (nullable = true)\n",
      " |-- registratie_datum_goedkeuring_afschrijvingsmoment_bpm_dt: string (nullable = true)\n",
      " |-- subcategorie_nederland: string (nullable = true)\n",
      " |-- taxi_indicator: string (nullable = true)\n",
      " |-- technische_max_massa_voertuig: string (nullable = true)\n",
      " |-- tellerstandoordeel: string (nullable = true)\n",
      " |-- tenaamstellen_mogelijk: string (nullable = true)\n",
      " |-- toegestane_maximum_massa_voertuig: string (nullable = true)\n",
      " |-- tweede_kleur: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- type_gasinstallatie: string (nullable = true)\n",
      " |-- typegoedkeuringsnummer: string (nullable = true)\n",
      " |-- uitvoering: string (nullable = true)\n",
      " |-- variant: string (nullable = true)\n",
      " |-- vermogen_massarijklaar: string (nullable = true)\n",
      " |-- verticale_belasting_koppelpunt_getrokken_voertuig: string (nullable = true)\n",
      " |-- vervaldatum_apk: string (nullable = true)\n",
      " |-- vervaldatum_apk_dt: string (nullable = true)\n",
      " |-- vervaldatum_tachograaf: string (nullable = true)\n",
      " |-- vervaldatum_tachograaf_dt: string (nullable = true)\n",
      " |-- voertuigsoort: string (nullable = true)\n",
      " |-- volgnummer_wijziging_eu_typegoedkeuring: string (nullable = true)\n",
      " |-- wacht_op_keuren: string (nullable = true)\n",
      " |-- wam_verzekerd: string (nullable = true)\n",
      " |-- wielbasis: string (nullable = true)\n",
      " |-- wielbasis_voertuig_maximum: string (nullable = true)\n",
      " |-- wielbasis_voertuig_minimum: string (nullable = true)\n",
      " |-- zuinigheidsclassificatie: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o181.sql.\n: org.apache.iceberg.exceptions.RESTException: Unable to process: Unable to find warehouse s3://warehouse/iceberg\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:250)\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:214)\n\tat org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:240)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:336)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:297)\n\tat org.apache.iceberg.rest.BaseHTTPClient.get(BaseHTTPClient.java:77)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.fetchConfig(RESTSessionCatalog.java:1023)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.initialize(RESTSessionCatalog.java:205)\n\tat org.apache.iceberg.rest.RESTCatalog.initialize(RESTCatalog.java:82)\n\tat org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:280)\n\tat org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:337)\n\tat org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:154)\n\tat org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:754)\n\tat org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:53)\n\tat scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:53)\n\tat org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n\tat org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:548)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m df.printSchema()\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 2) Namespace garanderen\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCREATE NAMESPACE IF NOT EXISTS \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mns_fqn\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# 3) Wegschrijven naar Iceberg Bronze (create or replace)\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müßä Schrijven naar Bronze tabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_fqn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py311/lib/python3.11/site-packages/pyspark/sql/session.py:1631\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m   1627\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1628\u001b[39m         litArgs = \u001b[38;5;28mself\u001b[39m._jvm.PythonUtils.toArray(\n\u001b[32m   1629\u001b[39m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[32m   1630\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1631\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jsparkSession\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlitArgs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m   1632\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1633\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py311/lib/python3.11/site-packages/py4j/java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py311/lib/python3.11/site-packages/pyspark/errors/exceptions/captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py311/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o181.sql.\n: org.apache.iceberg.exceptions.RESTException: Unable to process: Unable to find warehouse s3://warehouse/iceberg\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:250)\n\tat org.apache.iceberg.rest.ErrorHandlers$DefaultErrorHandler.accept(ErrorHandlers.java:214)\n\tat org.apache.iceberg.rest.HTTPClient.throwFailure(HTTPClient.java:240)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:336)\n\tat org.apache.iceberg.rest.HTTPClient.execute(HTTPClient.java:297)\n\tat org.apache.iceberg.rest.BaseHTTPClient.get(BaseHTTPClient.java:77)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.fetchConfig(RESTSessionCatalog.java:1023)\n\tat org.apache.iceberg.rest.RESTSessionCatalog.initialize(RESTSessionCatalog.java:205)\n\tat org.apache.iceberg.rest.RESTCatalog.initialize(RESTCatalog.java:82)\n\tat org.apache.iceberg.CatalogUtil.loadCatalog(CatalogUtil.java:280)\n\tat org.apache.iceberg.CatalogUtil.buildIcebergCatalog(CatalogUtil.java:337)\n\tat org.apache.iceberg.spark.SparkCatalog.buildIcebergCatalog(SparkCatalog.java:154)\n\tat org.apache.iceberg.spark.SparkCatalog.initialize(SparkCatalog.java:754)\n\tat org.apache.spark.sql.connector.catalog.Catalogs$.load(Catalogs.scala:65)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.$anonfun$catalog$1(CatalogManager.scala:53)\n\tat scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86)\n\tat org.apache.spark.sql.connector.catalog.CatalogManager.catalog(CatalogManager.scala:53)\n\tat org.apache.spark.sql.connector.catalog.LookupCatalog$CatalogAndNamespace$.unapply(LookupCatalog.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:51)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs$$anonfun$apply$1.applyOrElse(ResolveCatalogs.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$4(AnalysisHelper.scala:175)\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1215)\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1214)\n\tat org.apache.spark.sql.catalyst.plans.logical.CreateNamespace.mapChildren(v2Commands.scala:548)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:175)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators(AnalysisHelper.scala:76)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperators$(AnalysisHelper.scala:75)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:30)\n\tat org.apache.spark.sql.catalyst.analysis.ResolveCatalogs.apply(ResolveCatalogs.scala:27)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:222)\n\tat scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)\n\tat scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)\n\tat scala.collection.immutable.List.foldLeft(List.scala:91)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:219)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:211)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:211)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:226)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:222)\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:222)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:182)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:89)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:182)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:209)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:77)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:219)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:546)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:219)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:218)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:77)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:638)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:629)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:659)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# üîÑ Ingest van Landingzone ‚Üí Bronze (Iceberg via Polaris)\n",
    "# ======================================================================\n",
    "\n",
    "bucket = \"warehouse\"\n",
    "prefix = \"landing\"\n",
    "local_file = find_data_file(\"gekentekendevoertuigen_sample.json\")\n",
    "object_key = f\"{prefix}/{local_file.name}\"\n",
    "s3_uri = f\"s3a://{bucket}/{object_key}\"\n",
    "\n",
    "catalog = \"polaris\"\n",
    "namespace = \"bronze\"\n",
    "table_name = \"gekentekendevoertuigen\"\n",
    "\n",
    "ns_fqn = f\"{catalog}.{namespace}\"\n",
    "table_fqn = f\"{ns_fqn}.{table_name}\"\n",
    "\n",
    "print(f\"üì• Lezen vanuit landingzone: {s3_uri}\")\n",
    "\n",
    "# 0) Quick sanity: catalog zichtbaar?\n",
    "spark.sql(\"SHOW CATALOGS\").show(truncate=False)\n",
    "\n",
    "# 1) Data inlezen uit landingzone\n",
    "df = spark.read.option(\"multiline\", \"true\").json(s3_uri)\n",
    "\n",
    "print(f\"üì¶ Aantal records geladen: {df.count():,}\")\n",
    "df.printSchema()\n",
    "\n",
    "# 2) Namespace garanderen\n",
    "spark.sql(f\"CREATE NAMESPACE IF NOT EXISTS {ns_fqn}\")\n",
    "\n",
    "# 3) Wegschrijven naar Iceberg Bronze (create or replace)\n",
    "print(f\"üßä Schrijven naar Bronze tabel: {table_fqn}\")\n",
    "\n",
    "(\n",
    "    df.writeTo(table_fqn)\n",
    "      .using(\"iceberg\")\n",
    "      .option(\"format-version\", \"2\")\n",
    "      .createOrReplace()\n",
    ")\n",
    "\n",
    "# 4) Refresh metadata (handig bij interactive notebooks)\n",
    "spark.catalog.refreshTable(table_fqn)\n",
    "\n",
    "print(f\"‚úÖ Bronze tabel bijgewerkt: {table_fqn}\")\n",
    "\n",
    "# 5) Tabellen tonen\n",
    "print(f\"üìã Tabellen in {ns_fqn}:\")\n",
    "spark.sql(f\"SHOW TABLES IN {ns_fqn}\").show(truncate=False)\n",
    "\n",
    "# 6) Bronze teruglezen ter controle\n",
    "bronze_df = spark.read.table(table_fqn)\n",
    "\n",
    "print(f\"üîÅ Records in Bronze: {bronze_df.count():,}\")\n",
    "bronze_df.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query de bronze table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöó Top 5 voertuigsoorten:\n",
      "+--------------------+-----+\n",
      "|voertuigsoort       |count|\n",
      "+--------------------+-----+\n",
      "|Personenauto        |7078 |\n",
      "|Bedrijfsauto        |1237 |\n",
      "|Bromfiets           |782  |\n",
      "|Motorfiets          |258  |\n",
      "|Middenasaanhangwagen|136  |\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üè∑Ô∏è Top 5 merken:\n",
      "+-------------+-----+\n",
      "|merk         |count|\n",
      "+-------------+-----+\n",
      "|VOLKSWAGEN   |1076 |\n",
      "|PEUGEOT      |615  |\n",
      "|RENAULT      |606  |\n",
      "|MERCEDES-BENZ|565  |\n",
      "|FORD         |553  |\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "üî§ Top 5 handelsbenamingen:\n",
      "+---------------+-----+\n",
      "|handelsbenaming|count|\n",
      "+---------------+-----+\n",
      "|POLO           |219  |\n",
      "|GOLF           |202  |\n",
      "|FOCUS          |138  |\n",
      "|N/A            |135  |\n",
      "|CLIO           |125  |\n",
      "+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "‚ö° Top 5 voertuigen op vermogen (massarijklaar):\n",
      "+-------+--------------------+----------------------+\n",
      "|merk   |handelsbenaming     |vermogen_massarijklaar|\n",
      "+-------+--------------------+----------------------+\n",
      "|DUCATI |PANIGALE V4         |0.79                  |\n",
      "|YAMAHA |YZF-R1              |0.74                  |\n",
      "|YAMAHA |YZF1000             |0.73                  |\n",
      "|TRIUMPH|SPEED TRIPLE 1200 RR|0.67                  |\n",
      "|SUZUKI |GSX-R1000           |0.66                  |\n",
      "+-------+--------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = spark.read.table(\"polaris.bronze.gekentekendevoertuigen\")\n",
    "\n",
    "print(\"üöó Top 5 voertuigsoorten:\")\n",
    "(\n",
    "    df.groupBy(\"voertuigsoort\")\n",
    "      .count()\n",
    "      .orderBy(col(\"count\").desc())\n",
    "      .show(5, truncate=False)\n",
    ")\n",
    "\n",
    "print(\"\n",
    "üè∑Ô∏è Top 5 merken:\")\n",
    "(\n",
    "    df.groupBy(\"merk\")\n",
    "      .count()\n",
    "      .orderBy(col(\"count\").desc())\n",
    "      .show(5, truncate=False)\n",
    ")\n",
    "\n",
    "print(\"\n",
    "üî§ Top 5 handelsbenamingen:\")\n",
    "(\n",
    "    df.groupBy(\"handelsbenaming\")\n",
    "      .count()\n",
    "      .orderBy(col(\"count\").desc())\n",
    "      .show(5, truncate=False)\n",
    ")\n",
    "\n",
    "print(\"\n",
    "‚ö° Top 5 voertuigen op vermogen (massarijklaar):\")\n",
    "(\n",
    "    df.select(\"merk\", \"handelsbenaming\", \"vermogen_massarijklaar\")\n",
    "      .orderBy(col(\"vermogen_massarijklaar\").desc_nulls_last())\n",
    "      .show(5, truncate=False)\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lakehouse (Spark Driver)",
   "language": "python",
   "name": "lakehouse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
